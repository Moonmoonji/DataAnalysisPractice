---
title: "Assignment 4_문지원_20182480"
author: "문지원_20182480"
date: "2021 5 2 "
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>
```{r,echo=FALSE}
knitr::opts_chunk$set(error=TRUE)
```
### [Predicting Delayed Flights]

#### 1.다음의 순서로 data preprocessing을 진행하자.
```{r message=FALSE}
# 라이브러리 추가 
library(caret)
library(ISLR)
library(rsample)
library(psych)
library(glmnet)
library(dplyr)
library(ROCR)
library(e1071)
```

-- **항공기 출발시각이 6시 이전이거나 22시 이후인 데이터는 빈도수가 매우 적으므로 데이터셋에서 제외시킨다.**

<br/>
```{r message=FALSE}
flightdat <- read.csv("FlightRecords.csv")
flightdat <- flightdat[,c(10,3,8,4,2,9,13)]
str(flightdat)

flightdat <- subset(flightdat,deptime>600 & deptime<2000)
str(flightdat)
```
<br/>

-- **수치값으로 표현되어 있는 출발시각을 6시부터 22시까지 각 시간대를 나타내는 범주형 변수로 변환한다. **

<br/>
```{r message=FALSE}
flightdat$deptime <- as.factor(floor(flightdat$deptime/100))
str(flightdat)

```
<br/>

--**수치값으로 표현되어 있는 dayweek와 weather 변수를 factor로 변환한다. **

<br/>
```{r message=FALSE}
flightdat$dayweek <- as.factor(flightdat$dayweek)
flightdat$weather <- as.factor(flightdat$weather)
str(flightdat)
```
<br/>
-- **factor로 표현되어 있는 delay 변수가 가지는 level의 순서를 “ontime”, “delayed” 순으로 변환한다 (logistic regression 수행 시에 연착하는 경우를 로 만들기 위해서)**
<br/>

```{r}
flightdat$delay <- factor(flightdat$delay, levels=c("ontime","delayed"))
str(flightdat)
```
<br/>

#### 2. 요일 별 연착비율, 출발 시간대 별 연착 비율, 출발 공항 별 연착비율, 도착 공항 별 연착 비율, 항공사 별 연착비율, 날씨 별 연착 비율을 각각 그래프로 시각화해보자. 어떤 특성을 관찰할 수 있는가?

<br/>
```{r message=FALSE}
tb1<-table(flightdat$dayweek,flightdat$delay)
plot(tb1,main="요일 별 연착비율")

tb2<-table(flightdat$deptime,flightdat$delay)
plot(tb2,main="출발 시간대 별 연착 비율")

tb3<-table(flightdat$origin,flightdat$delay)
plot(tb3,main="출발 공항 별 연착비율")

tb4<-table(flightdat$dest,flightdat$delay)
plot(tb4,main="도착 공항 별 연착 비율")

tb5<-table(flightdat$carrier,flightdat$delay)
plot(tb5,main="항공사 별 연착비율")

tb6<-table(flightdat$weather,flightdat$delay)
plot(tb6,main="날씨 별 연착 비율")


```
<br/>

#### 3. 7개의 모든 변수들 간의 상관관계를 시각화해보자. 어떤 특성을 관찰할 수 있는가?
<br/>
```{r message=FALSE}
pairs.panels(flightdat)
```
<br/>
-- **해석** 
변수들 간의 상관관계가 모두 높지 않다. 상관관계가 0.5이상인 변수들이 없다. 
<br/>

#### 4. 데이터셋을 70:30 비율로 training set과 test set으로 분할하자. 이때 stratified sampling을 활용하여 두set에서 delay 변수의 분포가 크게 차이가 없도록 분할하자
<br/>
```{r}
set.seed(123)
split <- initial_split(flightdat,prop=0.7,strata = delay)
flight_train <- training(split)
flight_test <- testing(split) 
```
<br/>


#### 5. 데이터시각화로부터 weather 변수가 “Bad” 인 경우에는 항상 항공기가 연착되는 것을 관찰할 수 있다. 따라서 weather가 Bad이면 항공기가 연착되고, weather가 OK일 경우 항공기가 연착되지 않는 것으로 예측하는 단순한 모델을 baseline model이라 하자. Test set에 대해 baseline model을 적용했을 때 confusion matrix를 계산해 보세요
<br/>
```{r message=FALSE}
pred_base <- factor(sign(flight_test$weather==0),labels = c("delayed","ontime"))
confusionMatrix(pred_base,flight_test$delay)

```
<br/>

#### 6. Training set을 대상으로, 연착여부(delay)를 나머지 모든 변수를 사용하여 예측하기 위한 logistic regression model을 수립해보자. 
<br/>

```{r message=FALSE}
model1 <- glm(delay~.,data=flight_train,family="binomial")
summary(model1)

test_prob6 <- predict(model1,flight_test, type="response")


#threshold=0.2
test_pred6_1 <- rep("ontime",595)
test_pred6_1[test_prob6>0.2] <- "delayed"
confusionMatrix(factor(test_pred6_1,levels=c("ontime","delayed")),flight_test$delay)

#threshold=0.3
test_pred6_2 <- rep("ontime",595)
test_pred6_2[test_prob6>0.3] <- "delayed"
confusionMatrix(factor(test_pred6_2,levels=c("ontime","delayed")),flight_test$delay)

#threshold=0.5
test_pred6_3 <- rep("ontime",595)
test_pred6_3[test_prob6>0.5] <- "delayed"
confusionMatrix(factor(test_pred6_3,levels=c("ontime","delayed")),flight_test$delay)

#threshold=0.7
test_pred6_4 <- rep("ontime",595)
test_pred6_4[test_prob6>0.7] <- "delayed" 
confusionMatrix(factor(test_pred6_4,levels=c("ontime","delayed")),flight_test$delay)

```
<br/>

-- **변수 deptime19의 regression coefficient에 대한 추정값은 얼마인가? 이 추정값을 바탕으로 출발 시각이 19시대인 항공기에 대해서 어떠한 해석을 할 수 있는가? (Hint: 범주형 변수 deptime을 model에 추가할 때 deptime6을 제외한 deptime7 ~ deptime21에 대한 dummy 변수가 만들어진다.) ** 
<br/>
deptime19의 regression coefficient에 대한 추정값은 2.6292이다. 이 추정값을 바탕으로 출발 시각이 19시인 항공기라면 항공기가 연착될 확률의 odds는 exp(2.6292)=13.863배만큼 증가한다는 것을 알 수 있다. 
<br/>

-- **날씨에 문제가 없는 금요일 15시에 IAD에서 출발하여 JFK로 도착한 Delta 항공기가 연착될 확률은 얼마로 예측되는가?**

P(X)= ℮^(-0.102-0.371+2.01-0.82634-0.18871-1.46961) / (1+℮^(-0.102-0.371+2.01-0.82634-0.18871-1.46961) 
금요일, 15시, IAD, JFK, Delta, 날씨 좋음 에 해당하는 coefficient를 식에 대입해주었다. 해당하지 않는 coefficient에 대해서는 X=0을 대입하여 없애주었다. 

계산결과 확률값이 e^(-0.974) / (1+e^(-0.974)) = 0.2741 
따라서 연착확률은 27%이다. 
<br/>

-- **Threshold k=0.2,0.3,0.5,0.7 에 대해서 각각 test set에 대한 confusion matrix를 계산해 보자. 어떠한 경향을 관찰할 수 있는가?**
<br/>
threshold가 0.5일때가 accuracy가 최대가 되며 0.5이하에서는 threshold가 커질수록 accuracy가 증가하며 0.5 이상에서는 threshold가 커질수록 accuracy가 감소하는것을 알 수 있다. 
<br/>

-- **Baseline model과 logistic regression model의 성능을 비교해보자.**
<br/>
Baseline model은 모델 수립이 간단한데 비해서 정확도가 높다. Baseline model은 threshold가 0.5 이하인 logistic regression model보다 성능이 우수하다. 
<br/>
<br/>

#### 7. Training set을 대상으로, step() 함수를 활용한 backward stepwise selection을 적용하여 logistic regression model을 수립해보자.
<br/>
```{r message=FALSE}
#stepwise logistic regression
model_step <- step(model1, direction = "backward")

model2 <-glm(delay~dayweek+deptime+origin+carrier+weather,family="binomial",data=flight_train)
summary(model2)

test_prob7 <- predict(model2,flight_test, type="response")

#threshold=0.5
test_pred7_1 <- rep("ontime",595)
test_pred7_1[test_prob7>0.5] <- "delayed"
confusionMatrix(factor(test_pred7_1,levels=c("ontime","delayed")),flight_test$delay)
```
<br/>


-- **모델에 몇 개의 변수가 포함되었는가?**
<br/>
모델에 변수 5개가 포함되어있다. dayweek, deptime, origin, carrier, weather 변수가 포함되어있다. 

<br/>

-- **Threshold k=0.5 일때 test set에 대한 confusion matrix를 계산해 보자.**
<br/>
confusion matrix 계산 결과 accuracy가 0.8487로 계산되었다. 

<br/>

#### 8. Training set을 대상으로 Lasso regression을 적용하여 logistic regression model을 수립해보자. CV의결과 바탕으로 모델에 포함되는 feature의 수와 예측정확도를 모두 고려했을 때 적합한 모델을 선택하자
<br/>
```{r}
# Create feature matrix
trainX <- model.matrix(delay~., data=flight_train)[,-1]
trainY <- flight_train$delay

#Lasso Regression cross validation
set.seed(123)
lasso_model <- cv.glmnet(x=trainX , y=trainY, alpha=1, family="binomial",type.measure="class",nfolds=10)
plot(lasso_model)

#print performance measure
lasso_model$cvm

#print lambda
lasso_model$lambda

#print number of nonzero variable
lasso_model$nzero

#print lambda when number of variable is 19
lambda<-lasso_model$lambda[30]

#print coefficient
coef(lasso_model,s=lambda)

# confusion matrix when threshold is 0.5
test_prob8 <- predict(lasso_model,newx = model.matrix(delay~.,data=flight_test)[,-1],s=lambda,type="response")
test_pred8_1 <- rep("ontime",595)
test_pred8_1[test_prob8>0.5] <- "delayed"
confusionMatrix(factor(test_pred8_1,levels=c("ontime","delayed")),flight_test$delay)
```
<br/>


-- **모델에 어떠한 변수들이 포함되었는가?**
<br/>
lasso regression을 수행한 결과 변수가 30개 포함되어있을 때와 19개 포함되어있을 때의 정확도 차이가 크지 않으므로 변수 19개를 선택해주었다.
선택된 변수들은 dayweek3,dayweek4,dayweek6, dayweek7, deptime8,deptime9, deptime12,deptime13, deptime14, deptime15,deptime16,deptime17, deptime18, deptime19, originDCA, carrierDL,carrierOH, carrierUS,weather1 이다. 
<br/>

-- **Threshold k=0.5 일때 test set에 대한 confusion matrix를 계산해 보자**
<br/>
threshold가 0.5일때 confusion matrix의 accuracy는 0.8437이다. 

<br/>

#### 9. 6, 7, 8번에서 수립한 logistic regression model들에 대해서, test set에 대한 성능을 나타내는 ROC Curve를 하나의 그래프로 시각화하고, AUC값을 비교해 보자.
<br/>

```{r message=FALSE} 
# number 6
pred1 <- prediction(test_prob6,flight_test$delay,c("ontime","delayed"))
perf1 <- performance(pred1,measure = "tpr",x.measure="fpr")
plot(perf1, col="darkred",lwd=3)
#compute auc
auc1 <- performance(pred1,measure="auc")
auc1@y.values


# number 7
pred2 <- prediction(test_prob7,flight_test$delay,c("ontime","delayed"))
perf2 <- performance(pred2,measure = "tpr",x.measure="fpr")
plot(perf2, col="darkblue",lwd=3,add=TRUE)
#compute auc
auc2 <- performance(pred2,measure="auc")
auc2@y.values

# number 8 
pred3 <- prediction(test_prob8,flight_test$delay,c("ontime","delayed"))
perf3 <- performance(pred3,measure = "tpr",x.measure="fpr")
plot(perf3, col="darkgreen",lwd=3,add=TRUE)

#compute auc
auc3 <- performance(pred3,measure="auc")
auc3@y.values
```
<br/>
**--darkred = 6번문제, darkblue = 7번문제, darkgreen = 8번문제의 auc 그래프이다. 계산된 auc 값을 보면 6번문제의 logistic regression model의 auc가 가장 높다. **

<br/>

#### 10. Training set을 대상으로 k-nn을 적용해보자. 이때 train() 함수를 사용한 cross validation으로 Accuracy가 가장 높은 best 값을 찾는다.
<br/>
```{r} 
cv <- trainControl(method="repeatedcv",number=5,repeats = 5)
tune_grid <- expand.grid(k=seq(1,99,2))
set.seed(123)
knn_fit <- train(data=flight_train,delay~.,method="knn",trControl=cv,tuneGrid=tune_grid)
knn_fit 
ggplot(knn_fit) + theme_bw()

# k=5일때 accuracy가 가장 큼. 
test_pred <- predict(knn_fit,flight_test)
confusionMatrix(test_pred,flight_test$delay)
```
<br/>


-- **best 값은 얼마인가**
<br/>
k=5일때가 accuracy가 최대가 되는 best 값이다. 
<br/>

-- **Test set에 대한 confusion matrix를 계산해 보자. 그리고 Test set에 대한 성능을 앞서 수립한 logistic regression model들과 비교해보자.**
<br/>
confusion matrix에서 확인한 결과 accuracy가 0.8319이다. 이는 앞서 수립한 Lasso regression을 적용한  logistic regression model과  , backward stepwise selection을 적용한  logistic regression model보다 정확도가 낮다. 
<br/>

### [OJ Dataset]

#### ISLR 패키지에 속해 있는 OJ 데이터셋은 Citrus Hill과 Minute Maid Orange Juice를 구매한 1,070명의 고객에대한 정보를 포함한다. 고객 및 제품 정보를 담고 있는 17개의 feature를 사용하여 고객이 두 제품 중 어떤 것을 구매할지(Purchase 변수) 예측하는 모델을 SVM을 활용하여 만들어본다. Linear, RBF, Polynomial Kernel을 사용한 SVM 모델을 만들어보고 성능을 비교해보자. 어떤 SVM 모델이 가장 좋은 성능을 보이는가

<br/>
```{r message=FALSE} 
data <- OJ
str(data)

set.seed(123)
splt <- initial_split(data,prop=0.5,strata = Purchase)
train <- training(splt)
test <- testing(splt) 

# Linear Kernel SVM
set.seed(123)
tune.out1 <- tune(svm,Purchase~.,data=train,kernel="linear",ranges=list(cost=10^(seq(-2,2))))
summary(tune.out1)
bestmodel <- tune.out1$best.model
ypred1 <- predict(bestmodel,test)
confusionMatrix(ypred1,test$Purchase)
# RBF Kernel
set.seed(123)
tune.out2 <- tune(svm,Purchase~.,data=train,kernel="radial",ranges=list(cost=c(0.01,0.1,1,10,100,1000),gamma=c(0.01,0.1,1,10,100)))
summary(tune.out2)
plot(tune.out2)
ypred2 <- predict(tune.out2$best.model,newdata=test)
confusionMatrix(ypred2,test$Purchase)

# Polynomial Kernel 
set.seed(123)
tune.out3 <- tune(svm,Purchase~.,data=train,kernel="polynomial",ranges=list(cost=c(0.1,1,10,100,1000),degree=c(2,3,4)))
summary(tune.out3)
ypred3 <- predict(tune.out3$best.model,newdata=test)
confusionMatrix(ypred3,test$Purchase)
```
<br/>
--**결과 해석**
linear kernel이 accuracy가 0.8296로 가장 높아 제일 좋은 성능을 보인다고 할 수 있다. 